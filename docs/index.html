<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Automatic Calibration of a Multi-Camera System with Limited Overlapping Fields of View for 3D Surgical Scene Reconstruction">
  <meta name="keywords" content="CalibProj, calib-proj, multi-camera calibration, 3D reconstruction, computer vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Automatic Calibration of a Multi-Camera System
with Limited Overlapping Fields of View for
3D Surgical Scene Reconstruction</title>

 
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css"> 
  <link rel="icon" href="./static/images/logo.png"> <!-- TODO change icon for page bar. -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
   
            
  
 


          <h1 class="title is-1 publication-title">CalibProj: Automatic Calibration of a Multi-Camera System
with Limited Overlapping Fields of View for
3D Surgical Scene Reconstruction</h1>
<img src="./static/images/logo.png"
                 alt="TODO" style="width: 20%;" />
          <h2 class="subtitle is-4 publication-subtitle">
            <span> IPCAI 2025 Extended Oral</span>
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/timflueckiger/"><b>Tim Flückiger</b></a><sup>1,2*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Kk_o9AYAAAAJ&hl=fr&oi=ao">Jonas Hein</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/valery-fischer/">Valery Fischer</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=nQ4B3BgAAAAJ&hl=fr">Philipp Fürnstahl</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=6JewdrMAAAAJ&hl=fr">Lilian Calvet</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Research in Orthopedic Computer Science, University Hospital Balgrist, University of Zurich, Switzerland,</span>
            <span class="author-block"><sup>2</sup>Computer Vision and Geometry Group, ETH Zurich, Switzerland,</span>
            <br>
            <span class="author-block"><sup>*</sup>Corresponding author</span>

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2501.16221"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/tflueckiger/calib-proj"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

               <span class="link-block">
                <a href="./static/TODO.pdf" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Poster</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
    <div class="container is-max-desktop is-centered">
        <div class="hero-body is-centered">
            <img src="./static/images/SDT_ORX_Illustration.png"
                 alt="TODO"/>
  
            <h2 class="subtitle has-text-centered">
                <p>Automatic external calibration of a multi-camera system using the projections of multi-scale markers (MSMs) on the operating room floor.
</p>
            </h2>
        </div>
    </div>
</section>






<section class="section">
  <div class="container is-max-desktop">

    <!-- Intro. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title is-3">Abstract</h2> -->
        <div class="content has-text-justified">
          We present  <span class="dnerf">CalibProj</span>, a Python toolkit for <b>automatically calibrating the positions and orientations of multiple cameras</b>, even when they have very limited field of view overlap or they have very different zoom levels. <b>Unlike traditional methods, this approach requires no manual intervention, checkerboards, or prior calibration expertise.</b>

<span class="dnerf">CalibProj</span> uses a ceiling-mounted projector to display specially designed multi-scale markers (MSMs)—2D patterns at varying sizes—onto the scene. These projected markers can be seen from multiple angles and distances, enabling cameras with different viewpoints and zoom settings to detect and extract accurate feature correspondences. <b>Importantly, the projector itself does not need to be calibrated.</b>

The system automatically estimates the external calibration parameters (position and orientation) of each camera using only the images they capture of the projected markers—no user input required.

This makes the system especially useful for:

<ul>
  <li>Surveillance systems with cameras mounted far apart</li>
  <li>Camera networks with different fields of view (e.g., in an operating room)</li>
  <li>Multi-zoom or pan-tilt-zoom (PTZ) camera installations</li>
</ul>
  
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
               The purpose of this study is to develop an automated and accurate external camera calibration method for multi-camera systems used in 3D surgical scene reconstruction (3D-SSR), eliminating the need for operator intervention or specialized expertise. The method specifically addresses the problem of limited overlapping fields of view caused by significant variations in optical zoom levels and camera locations. We contribute a novel, fast, and fully automatic calibration method based on the projection of multi-scale markers (MSMs) using a ceiling-mounted projector. MSMs consist of 2D patterns projected at varying scales, ensuring accurate extraction of well distributed point correspondences across significantly different viewpoints and zoom levels. Validation is performed using both synthetic and real data captured in a mock-up OR, with comparisons to traditional manual marker-based methods as well as markerless calibration methods. The method achieves accuracy comparable to manual, operator-dependent calibration methods while exhibiting higher robustness under conditions of significant differences in zoom levels. Additionally, we show that state-of-the-art Structure-from-Motion (SfM) pipelines are ineffective in 3D-SSR settings, even when additional texture is projected onto the OR floor. The use of a ceiling-mounted entry-level projector proves to be an effective alternative to operator-dependent, traditional marker-based methods, paving the way for fully automated 3D-SSR.

          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
         <div class="content">
        
          <video id="dollyzoom" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/sparse viewpoints.mp4"
                    type="video/mp4">
          </video>
     Example viewpoints (left: GoPro Hero 10 Black, right: ceiling-mounted Canon CR-N300 with strong optical zoom) with different camera locations and zoom levels inducing an appearing scale factor of up to 19x on the surgical scene.
        </div>
      </div>
    </div>


   


  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

      <!-- Calibration Setup -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Calibration Setup</h2>
        <img src="./static/images/setup.png"
              alt="TODO"/>
        <div class="has-text-centered">
          Overview of the proposed setup. Our multi-camera calibration system employs an entry-level projector (P, projection in blue). Cameras are highlighted in red. In this example, GoPro cameras placed in far field and in near field on surgical lamps, and a zoomed in Canon CR-N300 (C3) are employed.  Images from a farfield camera (C4, top) and a near field camera (C3, bottom) during the projection of the proposed MSM. Top: MSM is successfully detected (green cross) in the far-field view for a large scale projection (left) and not detected otherwise (right). Bottom: MSM is not detected in the near-field view for a large scale projection (left) and successfully detected otherwise (green cross in the right image), therefore providing one point correspondence between C3 and C4 through their shared imaged center. This operation is repeated, providing a set of dense and uniformly distributed point correspondences.
        </div>
        <br>
        <br>

      

      </div>
    </div>
    <!--/ Calibration Setup -->


    
    <!-- Demo -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Demo</h2>
          <div class="content">
        
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/projections_pp.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <!--/ Demo -->


      <!-- Application to 3D Human Pose Reconstruction -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Application to 3D Human Pose Reconstruction</h2>
        <img src="./static/images/corresp_3_views.png"
              alt="TODO"/>
        <div class="has-text-centered">
        <p><b>Top:</b> Examples of camera viewpoints used for 3D surgical scene reconstruction. From left to right: far-field camera C1 (ceiling-mounted GoPro), near-field camera C2 (surgical lamp-mounted GoPro), and near-field camera C3 (ceiling-mounted Canon CR-N300), zoomed in on the surgical field.</p>
        <p><b>Bottom:</b> Inter-viewpoint correspondences provided by our multi-camera calibration system, observed from the same viewpoints. From left to right: all correspondences seen by C1 (blue, green, and red), correspondences between C1 and C2 (green), and correspondences between C1 and C3 (red). The surgeon’s body and hand poses, represented by blue lines in the first row, are successfully reconstructed using the estimated camera poses.</p>
        </div>
        <br>
        <br>

        <div class="content">
          <video id="dollyzoom" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/sdt_3d_human_pose_with_inputs.mp4"
                    type="video/mp4">
          </video>
          <div class="has-text-centered">
          Application of our calibration method to 3D-SSR. <b>Left:</b> input videos from far-field camera (GoPro Hero 10 Black). <b>Right:</b> the surgeon’s body poses successfully reconstructed using camera poses computed with the proposed MSM-based calibration method. The reconstructed objects are integrated into the <a href="https://jonashein.github.io/surgerydigitization/">OR digital twin</a>.
          </div>
        </div>

      </div>
    </div>
    <!--/ Application to 3D Human Pose Reconstruction -->


    

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{TODO
  author    = {TODO},
  title     = {TODO},
  journal   = {TODO},
  year      = {TODO},
}</code></pre>
  </div>
</section>

<section class="section" id="Acknowledgements">
    <div class="container is-max-desktop content">
        <h2 class="title">Acknowledgements</h2>
        This work has been supported by the <a href="https://or-x.ch/" target="_blank" rel="noopener noreferrer">OR-X</a> - a swiss national research infrastructure for translational surgery - and associated funding by the University of Zurich and University Hospital Balgrist.
    </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      
      <a class="icon-link" href="https://www.linkedin.com/in/timflueckiger/" class="external-link" disabled>
        <i class="fab fa-linkedin"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
           <p>
              Website template from <a href="https://nerfies.github.io/" target="_blank">Nerfies</a>.
            </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
